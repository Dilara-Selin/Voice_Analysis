{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VERİLEN SES KAYITLARININ MFCC ÖZELLİKLERİNİN ÇIKARILMASI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Ses dosyalarınızı kaydettiğiniz klasör\n",
    "ses_dosyasi_klasoru = \"ses_verileri\"\n",
    "\n",
    "def ozellik_cikarma(file_path):\n",
    "    # Ses dosyasını yükleme\n",
    "    y, sr = librosa.load(file_path, duration=5)  # 5 saniye sınırlaması\n",
    "    # MFCC özelliklerini çıkarma\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    # Ortalama alarak sabit boyutlu bir vektör elde etme\n",
    "    return np.mean(mfcc, axis=1)\n",
    "\n",
    "# Tüm dosyalar için özellik çıkarma\n",
    "veri = []\n",
    "etiketler = []\n",
    "\n",
    "for file in os.listdir(ses_dosyasi_klasoru):\n",
    "    if file.endswith('.wav'):\n",
    "        file_path = os.path.join(ses_dosyasi_klasoru, file)\n",
    "        features = ozellik_cikarma(file_path)\n",
    "        veri.append(features)\n",
    "        etiketler.append(file.split('.')[0])  # Dosya adını etiket olarak kullanma\n",
    "\n",
    "veri = np.array(veri)\n",
    "etiketler = np.array(etiketler)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KAYDI VERİLEN KİSİNİN KİM OLDUGUNU BULMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model başarıyla eğitildi ve kaydedildi.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Tahmin edilen kişi: selin\n",
      "Test seti üzerindeki doğruluk(accuracy): 0.75\n",
      "Test seti üzerindeki F1 skoru: 0.80\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "import os\n",
    "SES_MODEL_FILE = \"ses_tanima_modeli.keras\"\n",
    "# Özellik çıkarma fonksiyonu\n",
    "def ozellik_cikarma(file_path):\n",
    "    y, sr = librosa.load(file_path, duration=5)  # Ses dosyasını yükleme\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)  # MFCC çıkarma\n",
    "    return np.mean(mfcc, axis=1)  # Ortalama ile sabit boyutlu vektör\n",
    "\n",
    "# Veriyi yükleme\n",
    "def veri_yukle(ses_klasoru):\n",
    "    veri = []\n",
    "    etiketler = []\n",
    "    for file in os.listdir(ses_klasoru):\n",
    "        if file.endswith('.wav'):\n",
    "            file_path = os.path.join(ses_klasoru, file)\n",
    "            features = ozellik_cikarma(file_path)\n",
    "            veri.append(features)\n",
    "            etiketler.append(file.split('_')[0])  # Kişi adı dosya adından alınır\n",
    "    return np.array(veri), np.array(etiketler)\n",
    "\n",
    "# Ses dosyalarının bulunduğu klasör\n",
    "ses_klasoru = \"ses_verileri\"\n",
    "X, y = veri_yukle(ses_klasoru)\n",
    "\n",
    "# Etiketleri sayısal forma dönüştürme\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Veriyi eğitim ve test olarak ayırma\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.25, random_state=42)\n",
    "\n",
    "# Veri türlerini kontrol etme ve düzeltme\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# Model oluşturma\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train.shape[1],)),  # Giriş: Özellik sayısı\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(len(np.unique(y_train)), activation='softmax')  # Çıkış: Kişi sayısı\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Modeli eğitme\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=4, validation_data=(X_test, y_test), verbose=0)\n",
    "\n",
    "# Modeli kaydetme\n",
    "model.save(\"SES_MODEL_FILE\")\n",
    "print(\"Model başarıyla eğitildi ve kaydedildi.\")\n",
    "\n",
    "# Yeni ses dosyasını tahmin etme\n",
    "def ses_tahmin_et(model_path, file_path, label_encoder):\n",
    "    model = load_model(model_path , compile=False)\n",
    "    features = ozellik_cikarma(file_path).reshape(1, -1)  # Model girişine uygun boyut\n",
    "    tahmin = model.predict(features)\n",
    "    tahmin_kisi = label_encoder.inverse_transform([np.argmax(tahmin)])\n",
    "    return tahmin_kisi[0]\n",
    "\n",
    "# Modelin doğruluğunu ve F1 skorunu değerlendirme\n",
    "y_pred = model.predict(X_test)  # Test verisi üzerindeki tahminler\n",
    "y_pred_class = np.argmax(y_pred, axis=1)  # Sınıf tahminlerini al (softmax sonucu)\n",
    "\n",
    "# F1 skoru hesaplama\n",
    "f1 = f1_score(y_test, y_pred_class, average='weighted')  # weighted: Sınıf dengesizliğini göz önünde bulundurur\n",
    "\n",
    "# Test için bir ses dosyası tahmini\n",
    "test_ses_dosyasi = \"ses_verileri/selin_05.wav\"  # Test edilecek dosya\n",
    "tahmin = ses_tahmin_et(\"SES_MODEL_FILE\", test_ses_dosyasi, le)\n",
    "print(f\"Tahmin edilen kişi: {tahmin}\")\n",
    "\n",
    "# Modelin doğruluğunu değerlendirme\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test seti üzerindeki doğruluk(accuracy): {accuracy:.2f}\")\n",
    "print(f\"Test seti üzerindeki F1 skoru: {f1:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model başarıyla eğitildi ve kaydedildi.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "Tahmin edilen kişi: guzel\n",
      "Test seti üzerindeki doğruluk(accuracy): 0.62\n",
      "Test seti üzerindeki F1 skoru: 0.62\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "import os\n",
    "\n",
    "# Özellik çıkarma fonksiyonu\n",
    "def ozellik_cikarma(file_path):\n",
    "    y, sr = librosa.load(file_path, duration=5)  # Ses dosyasını yükleme\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)  # MFCC çıkarma\n",
    "    return np.mean(mfcc, axis=1)  # Ortalama ile sabit boyutlu vektör\n",
    "\n",
    "# Veriyi yükleme\n",
    "def veri_yukle(ses_klasoru):\n",
    "    veri = []\n",
    "    etiketler = []\n",
    "    for file in os.listdir(ses_klasoru):\n",
    "        if file.endswith('.wav'):\n",
    "            file_path = os.path.join(ses_klasoru, file)\n",
    "            features = ozellik_cikarma(file_path)\n",
    "            veri.append(features)\n",
    "            etiketler.append(file.split('_')[0])  # Kişi adı dosya adından alınır\n",
    "    return np.array(veri), np.array(etiketler)\n",
    "\n",
    "# Ses dosyalarının bulunduğu klasör\n",
    "ses_klasoru = \"ses_verileri\"\n",
    "X, y = veri_yukle(ses_klasoru)\n",
    "\n",
    "# Etiketleri sayısal forma dönüştürme\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Veriyi eğitim ve test olarak ayırma\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.25, random_state=42)\n",
    "\n",
    "# Veri türlerini kontrol etme ve düzeltme\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# Model oluşturma\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train.shape[1],)),  # Giriş: Özellik sayısı\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(len(np.unique(y_train)), activation='softmax')  # Çıkış: Kişi sayısı\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Modeli eğitme\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=4, validation_data=(X_test, y_test), verbose=0)\n",
    "\n",
    "# Modeli kaydetme\n",
    "model.save(\"SES_MODEL_FILE\")\n",
    "print(\"Model başarıyla eğitildi ve kaydedildi.\")\n",
    "\n",
    "# Yeni ses dosyasını tahmin etme\n",
    "def ses_tahmin_et(model_path, file_path, label_encoder):\n",
    "    model = load_model(model_path , compile=False)\n",
    "    features = ozellik_cikarma(file_path).reshape(1, -1)  # Model girişine uygun boyut\n",
    "    tahmin = model.predict(features)\n",
    "    tahmin_kisi = label_encoder.inverse_transform([np.argmax(tahmin)])\n",
    "    return tahmin_kisi[0]\n",
    "\n",
    "# Modelin doğruluğunu ve F1 skorunu değerlendirme\n",
    "y_pred = model.predict(X_test)  # Test verisi üzerindeki tahminler\n",
    "y_pred_class = np.argmax(y_pred, axis=1)  # Sınıf tahminlerini al (softmax sonucu)\n",
    "\n",
    "# F1 skoru hesaplama\n",
    "f1 = f1_score(y_test, y_pred_class, average='weighted')  # weighted: Sınıf dengesizliğini göz önünde bulundurur\n",
    "\n",
    "# Test için bir ses dosyası tahmini\n",
    "test_ses_dosyasi = \"ses_verileri/selin_05.wav\"  # Test edilecek dosya\n",
    "tahmin = ses_tahmin_et(\"SES_MODEL_FILE\", test_ses_dosyasi, le)\n",
    "print(f\"Tahmin edilen kişi: {tahmin}\")\n",
    "\n",
    "# Modelin doğruluğunu değerlendirme\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test seti üzerindeki doğruluk(accuracy): {accuracy:.2f}\")\n",
    "print(f\"Test seti üzerindeki F1 skoru: {f1:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KONUŞAN KİSİNİN KİM OLDUGUNU ANLIK OLARAK BULMAK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kayıt başlıyor...\n",
      "Kayıt tamamlandı.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step\n",
      "Mikrofondan kaydedilen sesin tahmini: guzel\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import wave\n",
    "\n",
    "def ses_kaydet(output_file, sure=5, fs=44100):\n",
    "    print(\"Kayıt başlıyor...\")\n",
    "    kayit = sd.rec(int(sure * fs), samplerate=fs, channels=1, dtype='int16')\n",
    "    sd.wait()  # Kayıt tamamlanana kadar bekle\n",
    "    print(\"Kayıt tamamlandı.\")\n",
    "    \n",
    "    # Kaydı wav formatında kaydet\n",
    "    with wave.open(output_file, 'wb') as wf:\n",
    "        wf.setnchannels(1)  # Mono kanal\n",
    "        wf.setsampwidth(2)  # 16-bit\n",
    "        wf.setframerate(fs)\n",
    "        wf.writeframes(kayit.tobytes())\n",
    "\n",
    "# Mikrofondan kayıt yap ve tahmini gerçekleştir\n",
    "kayıt_dosyasi = \"mikrofon_kayit.wav\"\n",
    "ses_kaydet(kayıt_dosyasi)\n",
    "\n",
    "tahmin = ses_tahmin_et(\"SES_MODEL_FILE\", kayıt_dosyasi, le)\n",
    "print(f\"Mikrofondan kaydedilen sesin tahmini: {tahmin}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DUYGU VE KONU ANALİZİ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "Device set to use mps:0\n",
      "/opt/anaconda3/lib/python3.11/site-packages/transformers/pipelines/text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Audio file could not be read as PCM WAV, AIFF/AIFF-C, or Native FLAC; check if file is corrupted or in another format",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/speech_recognition/__init__.py:233\u001b[0m, in \u001b[0;36mAudioFile.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;66;03m# attempt to read the file as WAV\u001b[39;00m\n\u001b[0;32m--> 233\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maudio_reader \u001b[38;5;241m=\u001b[39m wave\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename_or_fileobject, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlittle_endian \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# RIFF WAV is a little-endian format (most ``audioop`` operations assume that the frames are stored in little-endian form)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/wave.py:631\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(f, mode)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 631\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Wave_read(f)\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/wave.py:283\u001b[0m, in \u001b[0;36mWave_read.__init__\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 283\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitfp(f)\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/wave.py:263\u001b[0m, in \u001b[0;36mWave_read.initfp\u001b[0;34m(self, file)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunkname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfmt \u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 263\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_fmt_chunk(chunk)\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fmt_chunk_read \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/wave.py:388\u001b[0m, in \u001b[0;36mWave_read._read_fmt_chunk\u001b[0;34m(self, chunk)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 388\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Error(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munknown format: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (wFormatTag,))\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nchannels:\n",
      "\u001b[0;31mError\u001b[0m: unknown format: 3",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/speech_recognition/__init__.py:238\u001b[0m, in \u001b[0;36mAudioFile.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;66;03m# attempt to read the file as AIFF\u001b[39;00m\n\u001b[0;32m--> 238\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maudio_reader \u001b[38;5;241m=\u001b[39m aifc\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename_or_fileobject, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlittle_endian \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# AIFF is a big-endian format\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/aifc.py:954\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(f, mode)\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 954\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Aifc_read(f)\n\u001b[1;32m    955\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/aifc.py:358\u001b[0m, in \u001b[0;36mAifc_read.__init__\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 358\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitfp(file_object)\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/aifc.py:322\u001b[0m, in \u001b[0;36mAifc_read.initfp\u001b[0;34m(self, file)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunk\u001b[38;5;241m.\u001b[39mgetname() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFORM\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 322\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Error(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile does not start with FORM id\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    323\u001b[0m formdata \u001b[38;5;241m=\u001b[39m chunk\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m4\u001b[39m)\n",
      "\u001b[0;31mError\u001b[0m: file does not start with FORM id",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/speech_recognition/__init__.py:264\u001b[0m, in \u001b[0;36mAudioFile.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 264\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maudio_reader \u001b[38;5;241m=\u001b[39m aifc\u001b[38;5;241m.\u001b[39mopen(aiff_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (aifc\u001b[38;5;241m.\u001b[39mError, \u001b[38;5;167;01mEOFError\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/aifc.py:954\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(f, mode)\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 954\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Aifc_read(f)\n\u001b[1;32m    955\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/aifc.py:364\u001b[0m, in \u001b[0;36mAifc_read.__init__\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;66;03m# assume it is an open file object already\u001b[39;00m\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitfp(f)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/aifc.py:320\u001b[0m, in \u001b[0;36mAifc_read.initfp\u001b[0;34m(self, file)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m file\n\u001b[0;32m--> 320\u001b[0m chunk \u001b[38;5;241m=\u001b[39m Chunk(file)\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunk\u001b[38;5;241m.\u001b[39mgetname() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFORM\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/chunk.py:67\u001b[0m, in \u001b[0;36mChunk.__init__\u001b[0;34m(self, file, align, bigendian, inclheader)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunkname) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[0;32m---> 67\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mEOFError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 68\u001b[0m\n\u001b[1;32m     65\u001b[0m wav_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmikrofon_kayit.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Path to the converted WAV file\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Ses dosyasını yazıya çevir\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m transcript \u001b[38;5;241m=\u001b[39m transcribe_audio(wav_file_path)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMetin:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28mprint\u001b[39m(transcript)\n",
      "Cell \u001b[0;32mIn[1], line 20\u001b[0m, in \u001b[0;36mtranscribe_audio\u001b[0;34m(audio_file_path)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03mVerilen ses dosyasını yazıya çevirir.\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     19\u001b[0m recognizer \u001b[38;5;241m=\u001b[39m sr\u001b[38;5;241m.\u001b[39mRecognizer()\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sr\u001b[38;5;241m.\u001b[39mAudioFile(audio_file_path) \u001b[38;5;28;01mas\u001b[39;00m source:\n\u001b[1;32m     21\u001b[0m     audio \u001b[38;5;241m=\u001b[39m recognizer\u001b[38;5;241m.\u001b[39mrecord(source)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# Google API ile ses dosyasını metne çevirme\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/speech_recognition/__init__.py:266\u001b[0m, in \u001b[0;36mAudioFile.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maudio_reader \u001b[38;5;241m=\u001b[39m aifc\u001b[38;5;241m.\u001b[39mopen(aiff_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    265\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m (aifc\u001b[38;5;241m.\u001b[39mError, \u001b[38;5;167;01mEOFError\u001b[39;00m):\n\u001b[0;32m--> 266\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAudio file could not be read as PCM WAV, AIFF/AIFF-C, or Native FLAC; check if file is corrupted or in another format\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    267\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlittle_endian \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# AIFF is a big-endian format\u001b[39;00m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maudio_reader\u001b[38;5;241m.\u001b[39mgetnchannels() \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAudio must be mono or stereo\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: Audio file could not be read as PCM WAV, AIFF/AIFF-C, or Native FLAC; check if file is corrupted or in another format"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "from pydub import AudioSegment\n",
    "from transformers import pipeline\n",
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "# MP3'ten WAV'a dönüştürme fonksiyonu\n",
    "def convert_mp3_to_wav(mp3_file_path, wav_file_path):\n",
    "    audio = AudioSegment.from_mp3(mp3_file_path)\n",
    "    audio.export(wav_file_path, format=\"wav\")\n",
    "\n",
    "# Ses dosyasını metne çevirme fonksiyonu\n",
    "def transcribe_audio(audio_file_path):\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.AudioFile(audio_file_path) as source:\n",
    "        audio = recognizer.record(source)\n",
    "    try:\n",
    "        transcript = recognizer.recognize_google(audio, language=\"tr-TR\")\n",
    "        return transcript\n",
    "    except sr.UnknownValueError:\n",
    "        return \"Ses anlaşılamadı\"\n",
    "    except sr.RequestError as e:\n",
    "        return f\"Sonuçlar istenemedi; {e}\"\n",
    "\n",
    "# Metni Türkçeden İngilizceye çevirme fonksiyonu\n",
    "def translate_to_english(text):\n",
    "    translation = GoogleTranslator(source='tr', target='en').translate(text)\n",
    "    return translation\n",
    "\n",
    "# Zero-shot sınıflandırma için transformer modeli\n",
    "topic_classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "sentiment_analyzer = pipeline(\"text-classification\", model=\"bhadresh-savani/bert-base-uncased-emotion\", return_all_scores=True)\n",
    "\n",
    "# Duygu etiketlerini Türkçeye çevirme\n",
    "emotion_translation = {\n",
    "    \"joy\": \"Mutluluk\",\n",
    "    \"anger\": \"Öfke\",\n",
    "    \"fear\": \"Korku\",\n",
    "    \"sadness\": \"Üzüntü\",\n",
    "    \"surprise\": \"Şaşkınlık\",\n",
    "    \"disgust\": \"Tiksinme\",\n",
    "    \"neutral\": \"Nötr\"\n",
    "}\n",
    "\n",
    "# Konu etiketlerini Türkçeye çevirme\n",
    "topic_translation = {\n",
    "    \"sport\": \"Spor\",\n",
    "    \"technology\": \"Teknoloji\",\n",
    "    \"health\": \"Sağlık\",\n",
    "    \"art\": \"Sanat\",\n",
    "    \"weather\": \"Hava Durumu\",\n",
    "    \"feelings\": \"Duygular\"\n",
    "}\n",
    "\n",
    "# Duygu Analizi Fonksiyonu\n",
    "def analyze_emotion(text):\n",
    "    results = sentiment_analyzer(text, truncation=True)\n",
    "    emotions = {result['label']: result['score'] for result in results[0]}\n",
    "    total = sum(emotions.values())\n",
    "    percentages = {emotion_translation.get(emotion, emotion): (score / total) * 100 for emotion, score in emotions.items()}\n",
    "    return percentages\n",
    "\n",
    "# Konu Analizi Fonksiyonu\n",
    "def analyze_topic(text):\n",
    "    topics = [\"sport\", \"technology\", \"health\", \"art\", \"weather\", \"feelings\"]\n",
    "    result = topic_classifier(text, candidate_labels=topics)\n",
    "    topic = topic_translation.get(result['labels'][0], result['labels'][0])\n",
    "    return topic, result['scores'][0]\n",
    "\n",
    "# Ana kod\n",
    "if __name__ == \"__main__\":\n",
    "    wav_file_path = \"mikrofon_kayit.wav\"  # Path to the converted WAV file\n",
    "\n",
    "    # Ses dosyasını yazıya çevir\n",
    "    transcript = transcribe_audio(wav_file_path)\n",
    "\n",
    "    print(\"\\nTranscript:\")\n",
    "    print(transcript)\n",
    "    \n",
    "    words = transcript.split()\n",
    "    word_count = len(words)\n",
    "    print(f\"\\nKelime Sayısı: {word_count}\")\n",
    "\n",
    "    # İngilizceye çevir\n",
    "    translated_text = translate_to_english(transcript)\n",
    "   \n",
    "    # Duygu Analizi\n",
    "    print(\"\\nDuygu Analizi:\")\n",
    "    if translated_text:\n",
    "        emotion_percentages = analyze_emotion(translated_text)\n",
    "        for emotion, percentage in emotion_percentages.items():\n",
    "            print(f\"{emotion}: %{percentage:.2f}\")\n",
    "    else:\n",
    "        print(\"Duygu analizi yapılamadı.\")\n",
    "\n",
    "    # Konu Analizi\n",
    "    print(\"\\nKonu Analizi:\")\n",
    "    topic, score = analyze_topic(translated_text)\n",
    "    print(f\"En uygun konu: {topic} (%{score*100:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
